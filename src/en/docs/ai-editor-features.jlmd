---
title: "âœ¨ AI features"
description: "Fix syntax errors with one click!"
tags: ["docs", "editor"]
layout: "md.jlmd"
order: 8
---

# Automatic syntax fixes

Pluto can help you fix syntax errors automatically! If you make a typo or your code doesn't parse, Pluto will offer a button to fix it for you automatically, powered by a cloud AI model.

> ðŸš¨ **Experimental!** This feature is available in Pluto v0.20.8 and above. See the [announcement PR](https://github.com/fonsp/Pluto.jl/pull/3201) for more details.


## How to use it

- When you hit a **syntax error** (e.g. missing `end`, typo in a function name), Pluto shows a button: **"Fix with AI"**.
- Click the button, and you'll see a prompt explaining what will happen, and you can choose whether you want to use the service.
- If you accept, Pluto will use a cloud AI model (currently Claude 3.5 haiku) to fix the error, and the cell will be updated with the new code.

<video src="https://github.com/user-attachments/assets/9abd41e1-0d54-4fc8-aef2-9e74c0799434" controls="controls" muted="muted" playsinline></video>



## Privacy
The first time that you use the feature, Pluto will show a message explaining the current privacy policy of the feature. This might change over time, so check Pluto for the current information. _(If the privacy policy changes in the future, you will be asked to accept the new policy.)_

The feature currently works **without sign-in**: you can use the feature directly in Pluto without creating an account.


## Feedback
Does this not work for you? Or do you have other feedback? Use the built-in feedback form in Pluto, or let us know on [GitHub](https://github.com/fonsp/Pluto.jl/issues).


# _(beta)_ AI Prompt generation
We notice that people often use Pluto side-by-side with other AI chat systems, like [chatgpt.com](https://chatgpt.com) or [claude.ai](https://claude.ai). This feature will make that workflow more effective!

There is a button to generate a prompt about a cell with context from your notebook. When you ask a question like "What does this code do?" or "Help me add a linear trendline", it helps to tell the AI model not just the code, but also code from other cells, packages, current output, etc. The prompt generation will automatically add the relevant context to the prompt, so you can get better answers from AI models.

<img src="$(root_url)/assets/img/ai prompt generation beta.png" alt="Screenshot of the AI prompt generation UI" width="950" height="826">

Here is a video of the feature in action:

<video src="$(root_url)/assets/img/ai context demo 1.mov" controls="controls" muted="muted" playsinline></video>


> ðŸš¨ **Experimental!** This feature is available in Pluto v0.20.9 and above, and is currently in beta. See the [announcement PR](https://github.com/fonsp/Pluto.jl/pull/3224) for more details.

## How to use it
In any cell in your notebook, click the _cell context menu_ in the top right of the cell TODO ICON, and click "Ask AI". This will open the prompt generation UI.

<img src="$(root_url)/assets/img/cell context ask ai.png" alt="Screenshot of the Cell Context Menu with the Ask AI option" width="788" height="382">

Now you see the prompt generation UI. If you want, you can type a question that is added to the prompt. When you press Enter or click the "Copy" button, the prompt is copied to your clipboard. You can paste it into an AI chat on another website, like [chatgpt.com](https://chatgpt.com) or [claude.ai](https://claude.ai).

## How does it work?
The prompt is auto-generated based on notebook context. Pluto uses **cell inputs**, some **cell outputs**, package information and the **reactive dependency graph** to generate a prompt. The important feature is that the reactive dependency graph is used to determine which cells are relevant to the current cell.

The prompt contains XML tags like `<pluto-ai-context-current-cell>`. These tags are completely made up, but they help AI models understand the structure of the generated prompt.

Try it out on a complicated notebook, and take a look at the generated prompt.


## Token limit
Most AI chat systems have a token limit, which limits the length of the prompt. Pluto will try to generate the best possible prompt that fits within a fixed token limit (currently 3000 tokens). If the token limit is reached, less context will be provided.




## Privacy
This feature does not use any LLMs or other web services, it just generates a prompt that you can use as you wish.

## Feedback
Does this not work for you? Or do you have other feedback? Use the built-in feedback form in Pluto, or let us know on [GitHub](https://github.com/fonsp/Pluto.jl/issues).








# Configuration

You can enable or disable Pluto's AI features with the `enable_ai_editor_features` setting. To turn off all features, set it to `false`:

```julia
Pluto.run(enable_ai_editor_features=false)
```

## ChatGPT block detection
Some AI features will be **disabled automatically** if Pluto detects that ChatGPT is blocked on your network. 

This is for universities/workplaces that don't allow LLM tools as a policy. If this university has already blocked the `chat.openai.com` (ChatGPT) domain, then Pluto will "go with the flow" and also not offer the AI service. *(We check ChatGPT regardless of which LLM is used by Pluto.)*

<a href="https://github.com/fonsp/Pluto.jl/pull/3211" class="arrow">More info</a>

## Blocking AI features in your course
Are you a teacher who wants to block AI features in your course? You have the following options:
- Ask your students to start Pluto with `Pluto.run(enable_ai_editor_features=false)`.
- Ask the system administrator to block ChatGPT: `chat.openai.com`

Does this not work for you? Or do you have other feedback? Let us know on [GitHub](https://github.com/fonsp/Pluto.jl/issues), or send Fons an email!
